{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eda06eb9-cde6-4370-b189-3d06ffe505c8",
   "metadata": {},
   "source": [
    "## Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8d91a73a-cde9-48a6-9d2a-83715ad64a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\") \n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from datetime import datetime\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from string import punctuation\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "pd.options.display.max_colwidth = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d6e65e5d-df2b-4db6-b866-6c473ed85919",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('./data/data.csv',usecols=['title', 'news'] ,encoding = \"ISO-8859-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6c291504-9f0c-46cc-aaee-9ce274ccaafc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>news</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Jack Carr recalls Gen. Eisenhower's D-Day memo about 'great and noble undertaking'</td>\n",
       "      <td>fox</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bruce Willis, Demi Moore avoided doing one thing while co-parenting, daughter says</td>\n",
       "      <td>fox</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Blinken meets Qatar PM, says Israeli actions are not 'retaliation,' but 'defending the lives of its people'</td>\n",
       "      <td>fox</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Emily Blunt says her âtoes curlâ?when people tell her their kids want to act: 'I want to say, donât do it!'</td>\n",
       "      <td>fox</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>'The View' co-host, CNN commentator Ana Navarro to host night 2 of Democratic National Convention</td>\n",
       "      <td>fox</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                              title  \\\n",
       "0                                Jack Carr recalls Gen. Eisenhower's D-Day memo about 'great and noble undertaking'   \n",
       "1                                Bruce Willis, Demi Moore avoided doing one thing while co-parenting, daughter says   \n",
       "2       Blinken meets Qatar PM, says Israeli actions are not 'retaliation,' but 'defending the lives of its people'   \n",
       "3  Emily Blunt says her âtoes curlâ?when people tell her their kids want to act: 'I want to say, donât do it!'   \n",
       "4                 'The View' co-host, CNN commentator Ana Navarro to host night 2 of Democratic National Convention   \n",
       "\n",
       "  news  \n",
       "0  fox  \n",
       "1  fox  \n",
       "2  fox  \n",
       "3  fox  \n",
       "4  fox  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7106c263-be37-4037-bdfc-8c8308e895fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\26656\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\26656\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def clean_text(text):\n",
    "    # Remove punctuation\n",
    "    words = word_tokenize(text.lower())\n",
    "    # Remove stop words and punctuation\n",
    "    words = [\n",
    "        word for word in words\n",
    "        if word.lower() not in stop_words and word not in punctuation and not re.search(r'\\d', word)\n",
    "    ]\n",
    "    \n",
    "    # Rejoin words\n",
    "    return ' '.join(words)\n",
    "\n",
    "# Apply the function to the 'title' column\n",
    "df['title'] = df['title'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e01e6fd5-9314-4000-b467-dd718bc77acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=21)\n",
    "X_train = train_df['title']\n",
    "y_train = train_df['news']\n",
    "X_test = test_df['title']\n",
    "y_test = test_df['news']\n",
    "y_train = y_train.apply(lambda x: 1 if x == 'fox' else 0)\n",
    "y_test = y_test.apply(lambda x: 1 if x == 'fox' else 0)\n",
    "accuracy_scores={}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d65ad3b-9185-4462-a6fe-1f33ede24ce2",
   "metadata": {},
   "source": [
    "## Word Embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e267400b-0c90-496d-b392-fe651525150a",
   "metadata": {},
   "source": [
    "### TF-IDF/ Bag of worsd/Bag of ngrams\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "12c31464-013a-4221-81d6-7d81ddb6c931",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Names: ['aapi' 'aaron' 'aarp' ... 'zucker' 'zuckerberg' 'zzz']\n",
      "7721\n",
      "Feature Names: ['aapi' 'aaron' 'aarp' ... 'zucker' 'zuckerberg' 'zzz']\n",
      "7721\n",
      "Feature Names: ['aapi' 'aapi owned' 'aapi owned food' ... 'zzz' 'zzz amazon'\n",
      " 'zzz amazon buys']\n",
      "53222\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer(max_features=10000) # Adjust max_features if needed\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = vectorizer.transform(X_test)\n",
    "print(\"Feature Names:\", vectorizer.get_feature_names_out())\n",
    "print(len(vectorizer.vocabulary_))\n",
    "\n",
    "vectorizer = CountVectorizer() # Adjust max_features if needed\n",
    "X_train_bow = vectorizer.fit_transform(X_train)\n",
    "X_test_bow = vectorizer.transform(X_test)\n",
    "print(\"Feature Names:\", vectorizer.get_feature_names_out())\n",
    "print(len(vectorizer.vocabulary_))\n",
    "\n",
    "vectorizer = CountVectorizer(ngram_range=(1, 3))  # Adjust max_features&ngram_range if needed\n",
    "# Fit and transform the training data, then transform the test data\n",
    "X_train_bong = vectorizer.fit_transform(X_train)\n",
    "X_test_bong = vectorizer.transform(X_test)\n",
    "# Display the feature names (words and n-grams)\n",
    "print(\"Feature Names:\", vectorizer.get_feature_names_out())\n",
    "print(len(vectorizer.vocabulary_))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9c46662-7c07-4a4f-b2dc-803a39153a46",
   "metadata": {},
   "source": [
    "### Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1564acd6-ea3b-4292-8aad-94cc07e179ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "#install scipy<1.13 to be compatible for gensim\n",
    "#!pip install \"scipy<1.13\"\n",
    "word2vec_model = KeyedVectors.load_word2vec_format('./data/GoogleNews-vectors-negative300.bin.gz', binary=True,limit=500000)\n",
    "\n",
    "# Tokenize your text data\n",
    "X_train_tokenized = [sentence.split() for sentence in X_train]\n",
    "X_test_tokenized = [sentence.split() for sentence in X_test]\n",
    "\n",
    "# Define a function to average word vectors for each sentence\n",
    "def average_word_vectors(sentence, model, vector_size):\n",
    "    words = [word for word in sentence if word in model]\n",
    "    return np.mean(model[words], axis=0)\n",
    "# Apply average word vectors on training and test sets\n",
    "X_train_word2vec = np.array([average_word_vectors(sentence, word2vec_model, 300) for sentence in X_train_tokenized])\n",
    "X_test_word2vec = np.array([average_word_vectors(sentence, word2vec_model, 300) for sentence in X_test_tokenized])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be0674db-2da7-4347-8552-25ce83fd4337",
   "metadata": {},
   "source": [
    "### Glove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "311c869b-a8cf-4185-9619-9c768ac05e8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_file = \"./data/glove.840B.300d.txt\"\n",
    "\n",
    "# Load GloVe embeddings\n",
    "def load_glove_embeddings(file_path):\n",
    "    embeddings = {}\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            values = line.strip().split(' ')\n",
    "            word = values[0]\n",
    "            try:\n",
    "                vector = np.asarray(values[1:], dtype=\"float32\")\n",
    "                embeddings[word] = vector\n",
    "            except ValueError:\n",
    "                print(f\"Skipping line with invalid vector for word: {word}\")\n",
    "    return embeddings\n",
    "glove_embeddings = load_glove_embeddings(glove_file)\n",
    "\n",
    "def sentence_to_glove(sentence, embeddings):\n",
    "    words = sentence.split()\n",
    "    vectors = [embeddings[word] for word in words if word in embeddings]\n",
    "    if vectors:\n",
    "        return np.mean(vectors, axis=0)\n",
    "    else:\n",
    "        return np.zeros(300)  # Return a zero vector if no words are in embeddings\n",
    "\n",
    "# Transform an entire dataset (e.g., train and test sets)\n",
    "X_train_glove = np.array([sentence_to_glove(sentence, glove_embeddings) for sentence in X_train])\n",
    "X_test_glove = np.array([sentence_to_glove(sentence, glove_embeddings) for sentence in X_test])\n",
    "\n",
    "glove_embeddings = load_glove_embeddings(glove_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84133d6c-d0d1-4ae4-8912-afed2401675d",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f54068e-2318-4174-b2a7-38583c2b141f",
   "metadata": {},
   "source": [
    "### LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5cc91140-2e3c-477f-8d7e-b8eed08941db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tfidf With Logistic Regression\n",
      "Accuracy: 0.7832\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.75      0.77       363\n",
      "           1       0.78      0.81      0.79       389\n",
      "\n",
      "    accuracy                           0.78       752\n",
      "   macro avg       0.78      0.78      0.78       752\n",
      "weighted avg       0.78      0.78      0.78       752\n",
      "\n",
      "Bag Of Word With Logistic Regression\n",
      "Accuracy: 0.7819\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.80      0.78       363\n",
      "           1       0.80      0.77      0.78       389\n",
      "\n",
      "    accuracy                           0.78       752\n",
      "   macro avg       0.78      0.78      0.78       752\n",
      "weighted avg       0.78      0.78      0.78       752\n",
      "\n",
      "Bag Of N Grams With Logistic Regression\n",
      "Accuracy: 0.7899\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.82      0.79       363\n",
      "           1       0.82      0.76      0.79       389\n",
      "\n",
      "    accuracy                           0.79       752\n",
      "   macro avg       0.79      0.79      0.79       752\n",
      "weighted avg       0.79      0.79      0.79       752\n",
      "\n",
      "Word2Vec With Logistic Regression\n",
      "Accuracy: 0.6888\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.65      0.67       363\n",
      "           1       0.69      0.72      0.71       389\n",
      "\n",
      "    accuracy                           0.69       752\n",
      "   macro avg       0.69      0.69      0.69       752\n",
      "weighted avg       0.69      0.69      0.69       752\n",
      "\n",
      "GloVe With Logistic Regression\n",
      "Accuracy: 0.7261\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.71      0.71       363\n",
      "           1       0.73      0.74      0.74       389\n",
      "\n",
      "    accuracy                           0.73       752\n",
      "   macro avg       0.73      0.73      0.73       752\n",
      "weighted avg       0.73      0.73      0.73       752\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression with TF-IDF\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train_tfidf, y_train)\n",
    "y_pred = model.predict(X_test_tfidf)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Tfidf With Logistic Regression\")\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "accuracy_scores[\"Tfidf With Logistic Regression\"] = accuracy\n",
    "\n",
    "# Logistic Regression with Bag of Words\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train_bow, y_train)\n",
    "y_pred = model.predict(X_test_bow)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Bag Of Word With Logistic Regression\")\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "accuracy_scores[\"Bag Of Word With Logistic Regression\"] = accuracy\n",
    "\n",
    "# Logistic Regression with Bag of N-Grams\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train_bong, y_train)\n",
    "y_pred = model.predict(X_test_bong)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Bag Of N Grams With Logistic Regression\")\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "accuracy_scores[\"Bag Of N Grams With Logistic Regression\"] = accuracy\n",
    "\n",
    "# Logistic Regression with Word2Vec\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train_word2vec, y_train)\n",
    "y_pred = model.predict(X_test_word2vec)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Word2Vec With Logistic Regression\")\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "accuracy_scores[\"Word2Vec With Logistic Regression\"] = accuracy\n",
    "\n",
    "# Logistic Regression with GloVe\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train_glove, y_train)\n",
    "y_pred = model.predict(X_test_glove)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"GloVe With Logistic Regression\")\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "accuracy_scores[\"GloVe With Logistic Regression\"] = accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c67027b3-faaf-4255-8fa6-f3bf8202a39a",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ad692f26-6935-4c5c-adca-2a5f38ae311e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TFIDF with Decision Tree\n",
      "Accuracy: 0.7194\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.76      0.72       363\n",
      "           1       0.75      0.68      0.71       389\n",
      "\n",
      "    accuracy                           0.72       752\n",
      "   macro avg       0.72      0.72      0.72       752\n",
      "weighted avg       0.72      0.72      0.72       752\n",
      "\n",
      "Bag of Words with Decision Tree\n",
      "Accuracy: 0.7340\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.74      0.73       363\n",
      "           1       0.75      0.72      0.74       389\n",
      "\n",
      "    accuracy                           0.73       752\n",
      "   macro avg       0.73      0.73      0.73       752\n",
      "weighted avg       0.73      0.73      0.73       752\n",
      "\n",
      "Bag of N-grams with Decision Tree\n",
      "Accuracy: 0.7553\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.72      0.74       363\n",
      "           1       0.75      0.78      0.77       389\n",
      "\n",
      "    accuracy                           0.76       752\n",
      "   macro avg       0.76      0.75      0.75       752\n",
      "weighted avg       0.76      0.76      0.76       752\n",
      "\n",
      "Word2Vec with Decision Tree\n",
      "Accuracy: 0.5918\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.61      0.59       363\n",
      "           1       0.61      0.58      0.59       389\n",
      "\n",
      "    accuracy                           0.59       752\n",
      "   macro avg       0.59      0.59      0.59       752\n",
      "weighted avg       0.59      0.59      0.59       752\n",
      "\n",
      "GloVe with Decision Tree\n",
      "Accuracy: 0.6104\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.60      0.60       363\n",
      "           1       0.62      0.62      0.62       389\n",
      "\n",
      "    accuracy                           0.61       752\n",
      "   macro avg       0.61      0.61      0.61       752\n",
      "weighted avg       0.61      0.61      0.61       752\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Decision Tree with TF-IDF\n",
    "dt_model = DecisionTreeClassifier()\n",
    "dt_model.fit(X_train_tfidf, y_train)\n",
    "y_pred_dt = dt_model.predict(X_test_tfidf)\n",
    "accuracy = accuracy_score(y_test, y_pred_dt)\n",
    "print(\"TFIDF with Decision Tree\")\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred_dt))\n",
    "accuracy_scores[\"TFIDF with Decision Tree\"] = accuracy\n",
    "\n",
    "# Decision Tree with Bag of Words\n",
    "dt_model = DecisionTreeClassifier()\n",
    "dt_model.fit(X_train_bow, y_train)\n",
    "y_pred_dt_bow = dt_model.predict(X_test_bow)\n",
    "accuracy = accuracy_score(y_test, y_pred_dt_bow)\n",
    "print(\"Bag of Words with Decision Tree\")\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred_dt_bow))\n",
    "accuracy_scores[\"Bag of Words with Decision Tree\"] = accuracy\n",
    "\n",
    "# Decision Tree with Bag of N-grams\n",
    "dt_model = DecisionTreeClassifier()\n",
    "dt_model.fit(X_train_bong, y_train)\n",
    "y_pred_dt_bong = dt_model.predict(X_test_bong)\n",
    "accuracy = accuracy_score(y_test, y_pred_dt_bong)\n",
    "print(\"Bag of N-grams with Decision Tree\")\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred_dt_bong))\n",
    "accuracy_scores[\"Bag of N-grams with Decision Tree\"] = accuracy\n",
    "\n",
    "# Decision Tree with Word2Vec\n",
    "dt_model = DecisionTreeClassifier()\n",
    "dt_model.fit(X_train_word2vec, y_train)\n",
    "y_pred_dt_word2vec = dt_model.predict(X_test_word2vec)\n",
    "accuracy = accuracy_score(y_test, y_pred_dt_word2vec)\n",
    "print(\"Word2Vec with Decision Tree\")\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred_dt_word2vec))\n",
    "accuracy_scores[\"Word2Vec With DecisionTree\"] = accuracy\n",
    "\n",
    "# Decision Tree with GloVe\n",
    "dt_model = DecisionTreeClassifier()\n",
    "dt_model.fit(X_train_glove, y_train)\n",
    "y_pred_dt_glove = dt_model.predict(X_test_glove)\n",
    "accuracy = accuracy_score(y_test, y_pred_dt_glove)\n",
    "print(\"GloVe with Decision Tree\")\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred_dt_glove))\n",
    "accuracy_scores[\"GloVe with Decision Tree\"] = accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97b8ce80-3405-4605-b7ee-fdd4cc5f7981",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "23e5725e-cfb3-40f3-b120-6bfac8054b00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TFIDF with Random Forest\n",
      "Accuracy: 0.7793\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.76      0.77       363\n",
      "           1       0.78      0.79      0.79       389\n",
      "\n",
      "    accuracy                           0.78       752\n",
      "   macro avg       0.78      0.78      0.78       752\n",
      "weighted avg       0.78      0.78      0.78       752\n",
      "\n",
      "Bag of Words with Random Forest\n",
      "Accuracy: 0.7580\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.82      0.77       363\n",
      "           1       0.81      0.70      0.75       389\n",
      "\n",
      "    accuracy                           0.76       752\n",
      "   macro avg       0.76      0.76      0.76       752\n",
      "weighted avg       0.76      0.76      0.76       752\n",
      "\n",
      "Bag of N-grams with Random Forest\n",
      "Accuracy: 0.7394\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.84      0.76       363\n",
      "           1       0.81      0.65      0.72       389\n",
      "\n",
      "    accuracy                           0.74       752\n",
      "   macro avg       0.75      0.74      0.74       752\n",
      "weighted avg       0.75      0.74      0.74       752\n",
      "\n",
      "Word2Vec with Random Forest\n",
      "Accuracy: 0.7181\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.73      0.72       363\n",
      "           1       0.74      0.70      0.72       389\n",
      "\n",
      "    accuracy                           0.72       752\n",
      "   macro avg       0.72      0.72      0.72       752\n",
      "weighted avg       0.72      0.72      0.72       752\n",
      "\n",
      "GloVe with Random Forest\n",
      "Accuracy: 0.7261\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.70      0.71       363\n",
      "           1       0.73      0.75      0.74       389\n",
      "\n",
      "    accuracy                           0.73       752\n",
      "   macro avg       0.73      0.73      0.73       752\n",
      "weighted avg       0.73      0.73      0.73       752\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Random Forest with TF-IDF\n",
    "rf_model = RandomForestClassifier()\n",
    "rf_model.fit(X_train_tfidf, y_train)\n",
    "y_pred_rf = rf_model.predict(X_test_tfidf)\n",
    "accuracy = accuracy_score(y_test, y_pred_rf)\n",
    "print(\"TFIDF with Random Forest\")\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred_rf))\n",
    "accuracy_scores[\"TFIDF with Random Forest\"] = accuracy\n",
    "\n",
    "# Random Forest with Bag of Words\n",
    "rf_model = RandomForestClassifier()\n",
    "rf_model.fit(X_train_bow, y_train)\n",
    "y_pred_rf_bow = rf_model.predict(X_test_bow)\n",
    "accuracy = accuracy_score(y_test, y_pred_rf_bow)\n",
    "print(\"Bag of Words with Random Forest\")\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred_rf_bow))\n",
    "accuracy_scores[\"Bag of Words with Random Forest\"] = accuracy\n",
    "\n",
    "# Random Forest with Bag of N-grams\n",
    "rf_model = RandomForestClassifier()\n",
    "rf_model.fit(X_train_bong, y_train)\n",
    "y_pred_rf_bong = rf_model.predict(X_test_bong)\n",
    "accuracy = accuracy_score(y_test, y_pred_rf_bong)\n",
    "print(\"Bag of N-grams with Random Forest\")\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred_rf_bong))\n",
    "accuracy_scores[\"Bag of N-grams with Random Forest\"] = accuracy\n",
    "\n",
    "# Random Forest with Word2Vec\n",
    "rf_model = RandomForestClassifier()\n",
    "rf_model.fit(X_train_word2vec, y_train)\n",
    "y_pred_rf_w2c = rf_model.predict(X_test_word2vec)\n",
    "accuracy = accuracy_score(y_test, y_pred_rf_w2c)\n",
    "print(\"Word2Vec with Random Forest\")\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred_rf_w2c))\n",
    "accuracy_scores[\"Word2Vec With RandomForest\"] = accuracy\n",
    "\n",
    "# Random Forest with GloVe\n",
    "rf_model = RandomForestClassifier()\n",
    "rf_model.fit(X_train_glove, y_train)\n",
    "y_pred_rf_glove = rf_model.predict(X_test_glove)\n",
    "accuracy = accuracy_score(y_test, y_pred_rf_glove)\n",
    "print(\"GloVe with Random Forest\")\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred_rf_glove))\n",
    "accuracy_scores[\"GloVe with Random Forest\"] = accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aee4f2d2-6d9d-4921-917c-417138843e15",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "502902cb-23fa-4a33-b244-ee7d9e24a6d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TFIDF with SVM\n",
      "Accuracy: 0.7939\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.76      0.78       363\n",
      "           1       0.79      0.83      0.81       389\n",
      "\n",
      "    accuracy                           0.79       752\n",
      "   macro avg       0.79      0.79      0.79       752\n",
      "weighted avg       0.79      0.79      0.79       752\n",
      "\n",
      "Bag of Words with SVM\n",
      "Accuracy: 0.7699\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.87      0.78       363\n",
      "           1       0.85      0.68      0.75       389\n",
      "\n",
      "    accuracy                           0.77       752\n",
      "   macro avg       0.78      0.77      0.77       752\n",
      "weighted avg       0.78      0.77      0.77       752\n",
      "\n",
      "Bag of N-grams with SVM\n",
      "Accuracy: 0.5399\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.99      0.67       363\n",
      "           1       0.91      0.12      0.22       389\n",
      "\n",
      "    accuracy                           0.54       752\n",
      "   macro avg       0.71      0.55      0.45       752\n",
      "weighted avg       0.72      0.54      0.44       752\n",
      "\n",
      "Word2Vec with SVM\n",
      "Accuracy: 0.7553\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.73      0.74       363\n",
      "           1       0.75      0.78      0.77       389\n",
      "\n",
      "    accuracy                           0.76       752\n",
      "   macro avg       0.76      0.75      0.75       752\n",
      "weighted avg       0.76      0.76      0.76       752\n",
      "\n",
      "GloVe with SVM\n",
      "Accuracy: 0.7487\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.67      0.72       363\n",
      "           1       0.73      0.83      0.77       389\n",
      "\n",
      "    accuracy                           0.75       752\n",
      "   macro avg       0.75      0.75      0.75       752\n",
      "weighted avg       0.75      0.75      0.75       752\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# SVM with TFIDF\n",
    "svm_model = SVC()\n",
    "svm_model.fit(X_train_tfidf, y_train)\n",
    "y_pred_svm = svm_model.predict(X_test_tfidf)\n",
    "accuracy = accuracy_score(y_test, y_pred_svm)\n",
    "print(\"TFIDF with SVM\")\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred_svm))\n",
    "accuracy_scores[\"TFIDF with SVM\"] = accuracy\n",
    "\n",
    "# SVM with Bag of Words\n",
    "svm_model = SVC()\n",
    "svm_model.fit(X_train_bow, y_train)\n",
    "y_pred_svm_bow = svm_model.predict(X_test_bow)\n",
    "accuracy = accuracy_score(y_test, y_pred_svm_bow)\n",
    "print(\"Bag of Words with SVM\")\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred_svm_bow))\n",
    "accuracy_scores[\"Bag of Words with SVM\"] = accuracy\n",
    "\n",
    "# SVM with Bag of N-grams\n",
    "svm_model = SVC()\n",
    "svm_model.fit(X_train_bong, y_train)\n",
    "y_pred_svm_bong = svm_model.predict(X_test_bong)\n",
    "accuracy = accuracy_score(y_test, y_pred_svm_bong)\n",
    "print(\"Bag of N-grams with SVM\")\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred_svm_bong))\n",
    "accuracy_scores[\"Bag of N-grams with SVM\"] = accuracy\n",
    "\n",
    "# SVM with Word2Vec\n",
    "svm_model = SVC()\n",
    "svm_model.fit(X_train_word2vec, y_train)\n",
    "y_pred_svm_w2v = svm_model.predict(X_test_word2vec)\n",
    "accuracy = accuracy_score(y_test, y_pred_svm_w2v)\n",
    "print(\"Word2Vec with SVM\")\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred_svm_w2v))\n",
    "accuracy_scores[\"Word2Vec With SVM\"] = accuracy\n",
    "\n",
    "# SVM with GloVe\n",
    "svm_model = SVC()\n",
    "svm_model.fit(X_train_glove, y_train)\n",
    "y_pred_svm_glove = svm_model.predict(X_test_glove)\n",
    "accuracy = accuracy_score(y_test, y_pred_svm_glove)\n",
    "print(\"GloVe with SVM\")\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred_svm_glove))\n",
    "accuracy_scores[\"GloVe with SVM\"] = accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15e26973-193c-45df-8496-18a10b874690",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "11ae28fd-b517-47e0-94c5-f4e7f420e9c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TFIDF with Naive Bayes\n",
      "Accuracy: 0.7793\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.78      0.77       363\n",
      "           1       0.79      0.78      0.78       389\n",
      "\n",
      "    accuracy                           0.78       752\n",
      "   macro avg       0.78      0.78      0.78       752\n",
      "weighted avg       0.78      0.78      0.78       752\n",
      "\n",
      "Bag of Words with Naive Bayes\n",
      "Accuracy: 0.7699\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.77      0.76       363\n",
      "           1       0.78      0.77      0.78       389\n",
      "\n",
      "    accuracy                           0.77       752\n",
      "   macro avg       0.77      0.77      0.77       752\n",
      "weighted avg       0.77      0.77      0.77       752\n",
      "\n",
      "Bag of N-grams with Naive Bayes\n",
      "Accuracy: 0.7846\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.78      0.78       363\n",
      "           1       0.79      0.79      0.79       389\n",
      "\n",
      "    accuracy                           0.78       752\n",
      "   macro avg       0.78      0.78      0.78       752\n",
      "weighted avg       0.78      0.78      0.78       752\n",
      "\n",
      "Word2Vec with Naive Bayes (GaussianNB)\n",
      "Accuracy: 0.6569\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.58      0.62       363\n",
      "           1       0.65      0.72      0.69       389\n",
      "\n",
      "    accuracy                           0.66       752\n",
      "   macro avg       0.66      0.65      0.65       752\n",
      "weighted avg       0.66      0.66      0.66       752\n",
      "\n",
      "GloVe with Naive Bayes (GaussianNB)\n",
      "Accuracy: 0.6609\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.56      0.62       363\n",
      "           1       0.65      0.75      0.70       389\n",
      "\n",
      "    accuracy                           0.66       752\n",
      "   macro avg       0.66      0.66      0.66       752\n",
      "weighted avg       0.66      0.66      0.66       752\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB, GaussianNB\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Naive Bayes with TF-IDF\n",
    "nb_model = MultinomialNB()\n",
    "nb_model.fit(X_train_tfidf, y_train)\n",
    "y_pred_nb_tfidf = nb_model.predict(X_test_tfidf)\n",
    "accuracy = accuracy_score(y_test, y_pred_nb_tfidf)\n",
    "print(\"TFIDF with Naive Bayes\")\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred_nb_tfidf))\n",
    "accuracy_scores[\"TFIDF with Naive Bayes\"] = accuracy\n",
    "\n",
    "# Naive Bayes with Bag of Words\n",
    "nb_model = MultinomialNB()\n",
    "nb_model.fit(X_train_bow, y_train)\n",
    "y_pred_nb_bow = nb_model.predict(X_test_bow)\n",
    "accuracy = accuracy_score(y_test, y_pred_nb_bow)\n",
    "print(\"Bag of Words with Naive Bayes\")\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred_nb_bow))\n",
    "accuracy_scores[\"Bag of Words with Naive Bayes\"] = accuracy\n",
    "\n",
    "# Naive Bayes with Bag of N-grams\n",
    "nb_model = MultinomialNB()\n",
    "nb_model.fit(X_train_bong, y_train)\n",
    "y_pred_nb_bong = nb_model.predict(X_test_bong)\n",
    "accuracy = accuracy_score(y_test, y_pred_nb_bong)\n",
    "print(\"Bag of N-grams with Naive Bayes\")\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred_nb_bong))\n",
    "accuracy_scores[\"Bag of N-grams with Naive Bayes\"] = accuracy\n",
    "\n",
    "# Naive Bayes with Word2Vec (using GaussianNB)\n",
    "nb_model = GaussianNB()\n",
    "nb_model.fit(X_train_word2vec, y_train)\n",
    "y_pred_nb_w2v = nb_model.predict(X_test_word2vec)\n",
    "accuracy = accuracy_score(y_test, y_pred_nb_w2v)\n",
    "print(\"Word2Vec with Naive Bayes (GaussianNB)\")\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred_nb_w2v))\n",
    "accuracy_scores[\"Word2Vec with Naive Bayes\"] = accuracy\n",
    "\n",
    "# Naive Bayes with GloVe (using GaussianNB)\n",
    "nb_model = GaussianNB()\n",
    "nb_model.fit(X_train_glove, y_train)\n",
    "y_pred_nb_glove = nb_model.predict(X_test_glove)\n",
    "accuracy = accuracy_score(y_test, y_pred_nb_glove)\n",
    "print(\"GloVe with Naive Bayes (GaussianNB)\")\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred_nb_glove))\n",
    "accuracy_scores[\"GloVe with Naive Bayes\"] = accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4eba3a75-8e33-4453-abaa-526413c02f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ranked_models = sorted(accuracy_scores.items(), key=lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a883f144-71ef-48c2-af43-00590f811235",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('TFIDF with SVM', 0.7938829787234043),\n",
       " ('Bag Of N Grams With Logistic Regression', 0.7898936170212766),\n",
       " ('Bag of N-grams with Naive Bayes', 0.7845744680851063),\n",
       " ('Tfidf With Logistic Regression', 0.7832446808510638),\n",
       " ('Bag Of Word With Logistic Regression', 0.7819148936170213),\n",
       " ('TFIDF with Random Forest', 0.7792553191489362),\n",
       " ('TFIDF with Naive Bayes', 0.7792553191489362),\n",
       " ('Bag of Words with SVM', 0.7699468085106383),\n",
       " ('Bag of Words with Naive Bayes', 0.7699468085106383),\n",
       " ('Bag of Words with Random Forest', 0.7579787234042553),\n",
       " ('Bag of N-grams with Decision Tree', 0.7553191489361702),\n",
       " ('Word2Vec With SVM', 0.7553191489361702),\n",
       " ('GloVe with SVM', 0.7486702127659575),\n",
       " ('Bag of N-grams with Random Forest', 0.7393617021276596),\n",
       " ('Bag of Words with Decision Tree', 0.7340425531914894),\n",
       " ('GloVe With Logistic Regression', 0.726063829787234),\n",
       " ('GloVe with Random Forest', 0.726063829787234),\n",
       " ('TFIDF with Decision Tree', 0.7194148936170213),\n",
       " ('Word2Vec With RandomForest', 0.7180851063829787),\n",
       " ('Word2Vec With Logistic Regression', 0.6888297872340425),\n",
       " ('GloVe with Naive Bayes', 0.660904255319149),\n",
       " ('Word2Vec with Naive Bayes', 0.6569148936170213),\n",
       " ('GloVe with Decision Tree', 0.6103723404255319),\n",
       " ('Word2Vec With DecisionTree', 0.5917553191489362),\n",
       " ('Bag of N-grams with SVM', 0.5398936170212766)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ranked_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e9e9a35-8788-451a-a1f8-d1b33506699b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
